# âœ… hiring.cafe Scraper - Setup Complete!

Your Puppeteer-based job scraper for hiring.cafe is ready to use! ğŸ‰

## ğŸ“¦ What Was Created

### Core Scraper Files

1. **`scrape-hiring-cafe.js`** - Main Puppeteer scraper
   - Navigates to hiring.cafe search pages
   - Waits for JavaScript to render
   - Extracts job listings with multiple fallback strategies
   - Outputs JSON in job-tool format

2. **`import-jobs.js`** - Batch import utility
   - Automatically imports scraped jobs into job-tool
   - Opens browser and uses localStorage
   - Skips duplicates automatically
   - Shows import progress

3. **`test-scraper.js`** - Test suite
   - Validates scraper logic with mock data
   - Ensures extraction works correctly
   - âœ… Currently passing all tests!

### Client-Side Scraper (Bonus)

4. **`../js/scrapers/hiring-cafe-scraper.js`** - Browser-based scraper
   - Can be run as a bookmarklet
   - Extracts jobs from the current page
   - Useful for debugging or manual scraping

### Documentation

5. **`README.md`** - Complete documentation
   - Detailed usage instructions
   - All command-line options
   - Troubleshooting guide
   - Future scraper plans

6. **`QUICKSTART.md`** - Quick start guide
   - 3-step setup process
   - Common examples
   - Pro tips
   - Troubleshooting

7. **`SETUP-COMPLETE.md`** - This file!
   - Summary of what was created
   - Quick commands
   - Next steps

## ğŸš€ Quick Commands

```bash
# Test the scraper (verify it works)
npm run test:scraper

# Get help on all options
npm run scrape:help

# Scrape jobs from hiring.cafe (replace URL)
npm run scrape:hiring-cafe "https://hiring.cafe/?searchState=..."

# Import scraped jobs automatically
npm run import:jobs scrapers/hiring-cafe-jobs-[timestamp].json
```

## ğŸ¯ Complete Workflow Example

Here's a full end-to-end example:

```bash
# 1. Make sure you're in the project directory
cd /home/cdr/domains/cdr2.com/www/job-tool

# 2. Test that everything works
npm run test:scraper

# 3. Go to hiring.cafe and do a search:
#    - Visit: https://hiring.cafe/
#    - Search: "software engineering manager"
#    - Location: "San Francisco, CA"
#    - Copy the URL from your browser

# 4. Run the scraper with your URL
npm run scrape:hiring-cafe "https://hiring.cafe/?searchState=%7B%22searchQuery%22%3A%22software+engineering+manager%22%2C%22locations%22%3A%5B%7B%22id%22%3A%226xk1yZQBoEtHp_8Uv-2X%22%2C%22types%22%3A%5B%22locality%22%5D%2C%22address_components%22%3A%5B%7B%22long_name%22%3A%22San+Francisco%22%2C%22short_name%22%3A%22San+Francisco%22%2C%22types%22%3A%5B%22locality%22%5D%7D%2C%7B%22long_name%22%3A%22California%22%2C%22short_name%22%3A%22CA%22%2C%22types%22%3A%5B%22administrative_area_level_1%22%5D%7D%2C%7B%22long_name%22%3A%22United+States%22%2C%22short_name%22%3A%22US%22%2C%22types%22%3A%5B%22country%22%5D%7D%5D%2C%22geometry%22%3A%7B%22location%22%3A%7B%22lat%22%3A37.77493%2C%22lon%22%3A-122.41942%7D%7D%2C%22formatted_address%22%3A%22San+Francisco%2C+CA%2C+US%22%2C%22population%22%3A864816%2C%22workplace_types%22%3A%5B%5D%2C%22options%22%3A%7B%22radius%22%3A50%2C%22radius_unit%22%3A%22miles%22%2C%22ignore_radius%22%3Afalse%7D%7D%5D%7D"

# Output will show something like:
# ğŸš€ Starting hiring.cafe scraper...
# ğŸŒ Navigating to hiring.cafe...
# â³ Waiting for page to render...
# ğŸ“œ Scrolling to load more jobs...
# ğŸ” Extracting job data...
# âœ… Found 47 jobs!
# ğŸ’¾ Saved 47 jobs to: scrapers/hiring-cafe-jobs-2025-01-15T10-30-15.json

# 5. Import the jobs (browser will open automatically)
npm run import:jobs scrapers/hiring-cafe-jobs-2025-01-15T10-30-15.json

# 6. Open your job-tool and see the imported jobs!
# Open: https://cdr2.com/job-tool/app.html
# Or: file:///home/cdr/domains/cdr2.com/www/job-tool/app.html
```

## ğŸ“Š What Gets Scraped

Each job includes:

- âœ… **Title** - Job position title
- âœ… **Company** - Company name
- âœ… **Location** - City, state, or "Remote"
- âœ… **URL** - Direct link to job posting
- âœ… **Description** - Job description/summary
- âœ… **Salary** - Salary range (if available)
- âœ… **Job Type** - Remote/Hybrid/Onsite (if available)
- âœ… **Source** - Tagged as "hiring.cafe"
- âœ… **Metadata** - Created date, status, etc.

## ğŸ”§ Advanced Usage

### Watch the Scraper Work

See the browser in action (useful for debugging):

```bash
node scrapers/scrape-hiring-cafe.js --headless=false "https://hiring.cafe/..."
```

### Fast Scraping

Skip some scrolling for faster results:

```bash
node scrapers/scrape-hiring-cafe.js \
  --wait=3000 \
  --scroll-delay=500 \
  --max-scrolls=2 \
  "https://hiring.cafe/..."
```

### Custom Output Location

```bash
node scrapers/scrape-hiring-cafe.js \
  --output=../my-jobs/sf-engineering-jobs.json \
  "https://hiring.cafe/..."
```

### Multiple Searches

Scrape different searches and import them all:

```bash
# Engineering in SF
npm run scrape:hiring-cafe "https://hiring.cafe/?search=engineering&location=sf"

# Engineering in NYC
npm run scrape:hiring-cafe "https://hiring.cafe/?search=engineering&location=nyc"

# Remote engineering
npm run scrape:hiring-cafe "https://hiring.cafe/?search=engineering&remote=true"

# Import all at once
npm run import:jobs scrapers/hiring-cafe-jobs-*.json
```

## ğŸ“ How It Works

1. **Puppeteer launches Chrome** - Starts a headless browser instance
2. **Navigate to URL** - Goes to your hiring.cafe search page
3. **Wait for JavaScript** - Lets the React/SPA render (5 seconds by default)
4. **Auto-scroll** - Scrolls down to load lazy-loaded content (5 times by default)
5. **Extract with fallbacks** - Uses multiple CSS selectors to find job data
6. **Format to JSON** - Converts to job-tool format with all required fields
7. **Save to file** - Outputs timestamped JSON file ready for import

## ğŸ› Common Issues & Solutions

### Issue: No jobs found

**Check:** Are you on a search results page?
```bash
# âœ… Good: Search results URL
https://hiring.cafe/?searchState=%7B%22searchQuery%22%3A...

# âŒ Bad: Homepage
https://hiring.cafe/
```

**Solution:** Increase wait time
```bash
node scrapers/scrape-hiring-cafe.js --wait=10000 "URL"
```

### Issue: Browser won't launch

**Problem:** Missing Chrome/Chromium dependencies

**Solution (Ubuntu/Debian):**
```bash
sudo apt-get install -y chromium-browser
# OR
sudo apt-get install -y libx11-xcb1 libxcomposite1 libxcursor1 \
  libxdamage1 libxi6 libxtst6 libnss3 libcups2 libxss1 libxrandr2 \
  libasound2 libpangocairo-1.0-0 libatk1.0-0 libatk-bridge2.0-0 libgtk-3-0
```

### Issue: Rate limiting (429 errors)

**Problem:** Too many requests to hiring.cafe

**Solution:** Add delays and space out scrapes
```bash
node scrapers/scrape-hiring-cafe.js \
  --wait=8000 \
  --scroll-delay=2000 \
  "URL"
```

Wait 5-10 minutes between scraping sessions.

## ğŸ“š Full Documentation

- **Complete docs:** See `scrapers/README.md`
- **Quick start:** See `scrapers/QUICKSTART.md`
- **Command help:** `npm run scrape:help`

## ğŸ‰ Next Steps

1. **Test it out:** Run `npm run test:scraper` âœ… (Already passed!)
2. **Do a real scrape:** Get a hiring.cafe URL and try it
3. **Import jobs:** Use the import utility to load jobs into your tool
4. **Start applying:** Update job statuses, tailor resumes, track progress!

## ğŸ¤ Contributing

Want to add more scrapers? The pattern is established:

- LinkedIn Jobs
- Indeed
- Glassdoor
- AngelList/Wellfound
- RemoteOK
- We Work Remotely

Just follow the same structure as `scrape-hiring-cafe.js`!

---

**Happy job hunting! ğŸš€**

Questions? Check the README.md or run commands with `--help` flag.
